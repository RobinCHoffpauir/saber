{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mBad file descriptor (C:\\Users\\runneradmin\\AppData\\Local\\Temp\\tmpuk6z2au_\\build\\_deps\\bundled_libzmq-src\\src\\epoll.cpp:73). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import odds\n",
    "from helpers import *\n",
    "from datetime import datetime\n",
    "\n",
    "global team_names\n",
    "team_names = team_names = {\n",
    "    'BOS': 'Boston Red Sox',\n",
    "    'NYY': 'New York Yankees',\n",
    "    'TBR': 'Tampa Bay Rays',\n",
    "    'KCR': 'Kansas City Royals',\n",
    "    'CHW': 'Chicago White Sox',\n",
    "    'BAL': 'Baltimore Orioles',\n",
    "    'CLE': 'Cleveland Guardians',  # Updated from Indians\n",
    "    'MIN': 'Minnesota Twins',\n",
    "    'DET': 'Detroit Tigers',\n",
    "    'HOU': 'Houston Astros',\n",
    "    'LAA': 'Los Angeles Angels',\n",
    "    'SEA': 'Seattle Mariners',\n",
    "    'TEX': 'Texas Rangers',\n",
    "    'OAK': 'Oakland Athletics',\n",
    "    'WSN': 'Washington Nationals',\n",
    "    'MIA': 'Miami Marlins',\n",
    "    'ATL': 'Atlanta Braves',\n",
    "    'NYM': 'New York Mets',\n",
    "    'PHI': 'Philadelphia Phillies',\n",
    "    'CHC': 'Chicago Cubs',\n",
    "    'MIL': 'Milwaukee Brewers',\n",
    "    'STL': 'St. Louis Cardinals',\n",
    "    'PIT': 'Pittsburgh Pirates',\n",
    "    'CIN': 'Cincinnati Reds',\n",
    "    'LAD': 'Los Angeles Dodgers',\n",
    "    'ARI': 'Arizona Diamondbacks',\n",
    "    'COL': 'Colorado Rockies',\n",
    "    'SDP': 'San Diego Padres',\n",
    "    'SFG': 'San Francisco Giants',\n",
    "    'TOR': 'Toronto Blue Jays'\n",
    "}\n",
    "\n",
    "\n",
    "def get_covers():\n",
    "    # The URL to scrape\n",
    "    url = 'https://www.covers.com/sport/baseball/mlb/printsheet'\n",
    "    \n",
    "    today_date = datetime.today() \n",
    "    today_str = today_date.strftime('%Y-%m-%d')\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "      # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Initialize a list to store all rows data\n",
    "    table_data = []\n",
    "\n",
    "    # Find all 'tr' elements with the class 'highlight' or 'odd-rows'\n",
    "    rows = soup.find_all('tr', class_=['highlight', 'odd-rows'])\n",
    "\n",
    "    # Iterate over each row\n",
    "    for row in rows:\n",
    "        # For each 'tr' element, find all 'td' elements and extract the text\n",
    "        cols = row.find_all('td')\n",
    "        cols_text = [col.text.strip() for col in cols]\n",
    "        table_data.append(cols_text)\n",
    "\n",
    "    # Define column names, assuming these are known and match the data provided\n",
    "    columns = [\n",
    "        'Game Number', 'Team', 'Pitcher', 'Rest', 'Season WL', 'Season ERA', \n",
    "        'Season WHIP', 'Last 3 WL', 'Last 3 IP', 'Last 3 ERA', 'Last 3 WHIP', \n",
    "        'K', 'HR', 'Team WLCS', 'Streak WL', 'Streak O/U'\n",
    "    ]\n",
    "\n",
    "    # Create a dataframe importing the CSV file from ../data/elo/2024_elo.csv\n",
    "    elo = pd.read_csv(f'../../data/elo/2024_elo.csv')\n",
    "\n",
    "    # Create a DataFrame using table_data\n",
    "    df = pd.DataFrame(table_data, columns=columns)\n",
    "    df = pd.merge(df, elo, on='Team')\n",
    "    \n",
    "    df['outcome_name'] = df['Team'].map(team_names)\n",
    "    df = df.drop(['Game Number','Team'],axis=1)\n",
    "    df.to_csv(f'../../data/covers/{str(today_str)}_covers.csv')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # This will show the first few rows, use df to show the full DataFrame\n",
    "    odds = pd.read_csv(f'../../data/odds/{str(today_str)}_odds.csv')\n",
    "    merged_df = pd.merge(df, odds, on=['outcome_name'])\n",
    "    merged_df.index = merged_df['outcome_name']\n",
    "    merged_df = merged_df.drop('outcome_name',axis=1)\n",
    "    merged_df.to_csv(f'../../data/preview/{str(today_str)}_preview.csv')\n",
    "    print('Merged DataFrame and saved to csv: Completed!')\n",
    "\n",
    "def main():\n",
    "    get_covers()\n",
    "    print('Covers Data Retrieved and Saved!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
